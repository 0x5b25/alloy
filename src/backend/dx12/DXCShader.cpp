#include "DXCShader.hpp"

namespace Veldrid::VK::priv{

std::vector<uint8_t> shader_compile_binary_from_spirv(
        const std::vector<ShaderStageSPIRVData> &p_spirv, const std::string &p_shader_name){
            D3D12_ROOT_PARAMETER1 p;
    //SpirvReflectionData spirv_data;

    std::vector<ShaderResource> spirv_data;

	if (!SPIRVReflection::reflect_shader_resources(p_spirv, spirv_data, {})) {
		return Vector<uint8_t>();
	}

	// Collect reflection data into binary data.
	RenderingDeviceD3D12ShaderBinaryData binary_data = {};
	Vector<Vector<RenderingDeviceD3D12ShaderBinaryDataBinding>> uniform_info;
	Vector<RenderingDeviceD3D12ShaderBinarySpecializationConstant> specialization_constants;
	{
		binary_data.vertex_input_mask = spirv_data.vertex_input_mask;
		binary_data.fragment_output_mask = spirv_data.fragment_output_mask;
		binary_data.specialization_constants_count = spirv_data.specialization_constants.size();
		binary_data.is_compute = spirv_data.is_compute;
		binary_data.compute_local_size[0] = spirv_data.compute_local_size[0];
		binary_data.compute_local_size[1] = spirv_data.compute_local_size[1];
		binary_data.compute_local_size[2] = spirv_data.compute_local_size[2];
		binary_data.set_count = spirv_data.uniforms.size();
		binary_data.push_constant_size = spirv_data.push_constant_size;
		binary_data.nir_runtime_data_root_param_idx = UINT32_MAX;
		binary_data.stage_count = p_spirv.size();

		for (const Vector<SpirvReflectionData::Uniform> &spirv_set : spirv_data.uniforms) {
			Vector<RenderingDeviceD3D12ShaderBinaryDataBinding> set_bindings;
			for (const SpirvReflectionData::Uniform &spirv_uniform : spirv_set) {
				RenderingDeviceD3D12ShaderBinaryDataBinding binding{};
				binding.type = (uint32_t)spirv_uniform.type;
				binding.binding = spirv_uniform.binding;
				binding.stages = (uint32_t)spirv_uniform.stages_mask;
				binding.length = spirv_uniform.length;
				binding.writable = (uint32_t)spirv_uniform.writable;
				set_bindings.push_back(binding);
			}
			uniform_info.push_back(set_bindings);
		}

		for (const SpirvReflectionData::SpecializationConstant &spirv_sc : spirv_data.specialization_constants) {
			RenderingDeviceD3D12ShaderBinarySpecializationConstant spec_constant{};
			spec_constant.type = (uint32_t)spirv_sc.type;
			spec_constant.constant_id = spirv_sc.constant_id;
			spec_constant.int_value = spirv_sc.int_value;
			specialization_constants.push_back(spec_constant);

			binary_data.spirv_specialization_constants_ids_mask |= (1 << spirv_sc.constant_id);
		}
	}

	// Translate SPIR-V shaders to DXIL, and collect shader info from the new representation.
	std::unordered_map<Shader::Description::Stage, std::vector<uint8_t>> dxil_blobs;
	//BitField<ShaderStage> stages_processed;
    Shader::Description::Stage stages_processed {};
	{
		HashMap<int, nir_shader *> stages_nir_shaders;

		auto free_nir_shaders = [&]() {
			for (KeyValue<int, nir_shader *> &E : stages_nir_shaders) {
				ralloc_free(E.value);
			}
			stages_nir_shaders.clear();
		};

		// This is based on spirv2dxil.c. May need updates when it changes.
		// Also, this has to stay around until after linking.
		nir_shader_compiler_options nir_options = *dxil_get_nir_compiler_options();
		nir_options.lower_base_vertex = false;

		dxil_spirv_runtime_conf dxil_runtime_conf = {};
		dxil_runtime_conf.runtime_data_cbv.register_space = RUNTIME_DATA_SPACE;
		dxil_runtime_conf.runtime_data_cbv.base_shader_register = RUNTIME_DATA_REGISTER;
		dxil_runtime_conf.push_constant_cbv.register_space = ROOT_CONSTANT_SPACE;
		dxil_runtime_conf.push_constant_cbv.base_shader_register = ROOT_CONSTANT_REGISTER;
		dxil_runtime_conf.zero_based_vertex_instance_id = true;
		dxil_runtime_conf.zero_based_compute_workgroup_id = true;
		dxil_runtime_conf.declared_read_only_images_as_srvs = true;
		// Making this explicit to let maintainers know that in practice this didn't improve performance,
		// probably because data generated by one shader and consumed by another one forces the resource
		// to transition from UAV to SRV, and back, instead of being an UAV all the time.
		// In case someone wants to try, care must be taken so in case of incompatible bindings across stages
		// happen as a result, all the stages are re-translated. That can happen if, for instance, a stage only
		// uses an allegedly writable resource only for reading but the next stage doesn't.
		dxil_runtime_conf.inferred_read_only_images_as_srvs = false;

		// - Translate SPIR-V to NIR.
		for (int i = 0; i < p_spirv.size(); i++) {
			ShaderStage stage = (ShaderStage)p_spirv[i].shader_stage;
			ShaderStage stage_flag = (ShaderStage)(1 << p_spirv[i].shader_stage);

			stages_processed.set_flag(stage_flag);

			{
				char *entry_point = "main";

				static const gl_shader_stage SPIRV_TO_MESA_STAGES[SHADER_STAGE_MAX] = {
					/* SHADER_STAGE_VERTEX */ MESA_SHADER_VERTEX,
					/* SHADER_STAGE_FRAGMENT */ MESA_SHADER_FRAGMENT,
					/* SHADER_STAGE_TESSELATION_CONTROL */ MESA_SHADER_TESS_CTRL,
					/* SHADER_STAGE_TESSELATION_EVALUATION */ MESA_SHADER_TESS_EVAL,
					/* SHADER_STAGE_COMPUTE */ MESA_SHADER_COMPUTE,
				};

				nir_shader *nir_shader = spirv_to_nir(
						(const uint32_t *)p_spirv[i].spir_v.ptr(),
						p_spirv[i].spir_v.size() / sizeof(uint32_t),
						nullptr,
						0,
						SPIRV_TO_MESA_STAGES[stage],
						entry_point,
						dxil_spirv_nir_get_spirv_options(), &nir_options);
				if (!nir_shader) {
					free_nir_shaders();
					ERR_FAIL_V_MSG(Vector<uint8_t>(), "Shader translation (step 1) at stage " + String(shader_stage_names[stage]) + " failed.");
				}

#ifdef DEV_ENABLED
				nir_validate_shader(nir_shader, "Validate before feeding NIR to the DXIL compiler");
#endif

				if (stage == SHADER_STAGE_VERTEX) {
					dxil_runtime_conf.yz_flip.y_mask = 0xffff;
					dxil_runtime_conf.yz_flip.mode = DXIL_SPIRV_Y_FLIP_UNCONDITIONAL;
				} else {
					dxil_runtime_conf.yz_flip.y_mask = 0;
					dxil_runtime_conf.yz_flip.mode = DXIL_SPIRV_YZ_FLIP_NONE;
				}

				// This is based on spirv2dxil.c. May need updates when it changes.
				dxil_spirv_nir_prep(nir_shader);
				bool requires_runtime_data = {};
				dxil_spirv_nir_passes(nir_shader, &dxil_runtime_conf, &requires_runtime_data);

				stages_nir_shaders[stage] = nir_shader;
			}
		}

		// - Link NIR shaders.
		for (int i = SHADER_STAGE_MAX - 1; i >= 0; i--) {
			if (!stages_nir_shaders.has(i)) {
				continue;
			}
			nir_shader *shader = stages_nir_shaders[i];
			nir_shader *prev_shader = nullptr;
			for (int j = i - 1; j >= 0; j--) {
				if (stages_nir_shaders.has(j)) {
					prev_shader = stages_nir_shaders[j];
					break;
				}
			}
			if (prev_shader) {
				bool requires_runtime_data = {};
				dxil_spirv_nir_link(shader, prev_shader, &dxil_runtime_conf, &requires_runtime_data);
			}
		}

		// - Translate NIR to DXIL.
		for (int i = 0; i < p_spirv.size(); i++) {
			ShaderStage stage = (ShaderStage)p_spirv[i].shader_stage;

			struct ShaderData {
				ShaderStage stage;
				RenderingDeviceD3D12ShaderBinaryData &binary_data;
				Vector<Vector<RenderingDeviceD3D12ShaderBinaryDataBinding>> &uniform_info;
				Vector<RenderingDeviceD3D12ShaderBinarySpecializationConstant> &specialization_constants;
			} shader_data{ stage, binary_data, uniform_info, specialization_constants };

			GodotNirCallbacks godot_nir_callbacks = {};
			godot_nir_callbacks.data = &shader_data;

			godot_nir_callbacks.report_resource = [](uint32_t p_register, uint32_t p_space, uint32_t p_dxil_type, void *p_data) {
				ShaderData &shader_data = *(ShaderData *)p_data;

				// Types based on Mesa's dxil_container.h.
				static const uint32_t DXIL_RES_SAMPLER = 1;
				static const ResourceClass DXIL_TYPE_TO_CLASS[] = {
					/* DXIL_RES_INVALID */ RES_CLASS_INVALID,
					/* DXIL_RES_SAMPLER */ RES_CLASS_INVALID, // Handling sampler as a flag.
					/* DXIL_RES_CBV */ RES_CLASS_CBV,
					/* DXIL_RES_SRV_TYPED */ RES_CLASS_SRV,
					/* DXIL_RES_SRV_RAW */ RES_CLASS_SRV,
					/* DXIL_RES_SRV_STRUCTURED */ RES_CLASS_SRV,
					/* DXIL_RES_UAV_TYPED */ RES_CLASS_UAV,
					/* DXIL_RES_UAV_RAW */ RES_CLASS_UAV,
					/* DXIL_RES_UAV_STRUCTURED */ RES_CLASS_UAV,
					/* DXIL_RES_UAV_STRUCTURED_WITH_COUNTER */ RES_CLASS_INVALID,
				};
				DEV_ASSERT(p_dxil_type < ARRAY_SIZE(DXIL_TYPE_TO_CLASS));
				ResourceClass res_class = DXIL_TYPE_TO_CLASS[p_dxil_type];

				if (p_register == ROOT_CONSTANT_REGISTER && p_space == ROOT_CONSTANT_SPACE) {
					DEV_ASSERT(res_class == RES_CLASS_CBV);
					shader_data.binary_data.dxil_push_constant_stages |= (1 << shader_data.stage);
				} else if (p_register == RUNTIME_DATA_REGISTER && p_space == RUNTIME_DATA_SPACE) {
					DEV_ASSERT(res_class == RES_CLASS_CBV);
					shader_data.binary_data.nir_runtime_data_root_param_idx = 1; // Temporary, to be determined later.
				} else {
					DEV_ASSERT(p_space == 0);

					uint32_t set = p_register / GODOT_NIR_DESCRIPTOR_SET_MULTIPLIER;
					uint32_t binding = (p_register % GODOT_NIR_DESCRIPTOR_SET_MULTIPLIER) / GODOT_NIR_BINDING_MULTIPLIER;

					DEV_ASSERT(set < (uint32_t)shader_data.uniform_info.size());
					bool found = false;
					for (int i = 0; i < shader_data.uniform_info[set].size(); i++) {
						if (shader_data.uniform_info[set][i].binding != binding) {
							continue;
						}

						RenderingDeviceD3D12ShaderBinaryDataBinding &binding_info = shader_data.uniform_info.write[set].write[i];

						binding_info.dxil_stages |= (1 << shader_data.stage);

						if (res_class != RES_CLASS_INVALID) {
							DEV_ASSERT(binding_info.res_class == (uint32_t)RES_CLASS_INVALID || binding_info.res_class == (uint32_t)res_class);
							binding_info.res_class = res_class;
						} else if (p_dxil_type == DXIL_RES_SAMPLER) {
							binding_info.has_sampler = (uint32_t) true;
						} else {
							CRASH_NOW();
						}

						found = true;
						break;
					}
					DEV_ASSERT(found);
				}
			};

			godot_nir_callbacks.report_sc_bit_offset_fn = [](uint32_t p_sc_id, uint64_t p_bit_offset, void *p_data) {
				ShaderData &shader_data = *(ShaderData *)p_data;

				bool found = false;
				for (int i = 0; i < shader_data.specialization_constants.size(); i++) {
					if (shader_data.specialization_constants[i].constant_id != p_sc_id) {
						continue;
					}

					uint32_t offset_idx = shader_stage_bit_offset_indices[shader_data.stage];
					DEV_ASSERT(shader_data.specialization_constants.write[i].stages_bit_offsets[offset_idx] == 0);
					shader_data.specialization_constants.write[i].stages_bit_offsets[offset_idx] = p_bit_offset;

					found = true;
					break;
				}
				DEV_ASSERT(found);
			};

			godot_nir_callbacks.report_bitcode_bit_offset_fn = [](uint64_t p_bit_offset, void *p_data) {
				DEV_ASSERT(p_bit_offset % 8 == 0);
				ShaderData &shader_data = *(ShaderData *)p_data;
				uint32_t offset_idx = shader_stage_bit_offset_indices[shader_data.stage];
				for (int i = 0; i < shader_data.specialization_constants.size(); i++) {
					if (shader_data.specialization_constants.write[i].stages_bit_offsets[offset_idx] == 0) {
						// This SC has been optimized out from this stage.
						continue;
					}
					shader_data.specialization_constants.write[i].stages_bit_offsets[offset_idx] += p_bit_offset;
				}
			};

			auto shader_model_d3d_to_dxil = [](D3D_SHADER_MODEL p_d3d_shader_model) -> dxil_shader_model {
				static_assert(SHADER_MODEL_6_0 == 0x60000);
				static_assert(SHADER_MODEL_6_3 == 0x60003);
				static_assert(D3D_SHADER_MODEL_6_0 == 0x60);
				static_assert(D3D_SHADER_MODEL_6_3 == 0x63);
				return (dxil_shader_model)((p_d3d_shader_model >> 4) * 0x10000 + (p_d3d_shader_model & 0xf));
			};

			nir_to_dxil_options nir_to_dxil_options = {};
			nir_to_dxil_options.environment = DXIL_ENVIRONMENT_VULKAN;
			nir_to_dxil_options.shader_model_max = shader_model_d3d_to_dxil(context->get_shader_capabilities().shader_model);
			nir_to_dxil_options.validator_version_max = dxil_get_validator_version(get_dxil_validator_for_current_thread());
			nir_to_dxil_options.godot_nir_callbacks = &godot_nir_callbacks;

			dxil_logger logger = {};
			logger.log = [](void *p_priv, const char *p_msg) {
#ifdef DEBUG_ENABLED
				print_verbose(p_msg);
#endif
			};

			blob dxil_blob = {};
			bool ok = nir_to_dxil(stages_nir_shaders[stage], &nir_to_dxil_options, &logger, &dxil_blob);
			ralloc_free(stages_nir_shaders[stage]);
			stages_nir_shaders.erase(stage);
			if (!ok) {
				free_nir_shaders();
				ERR_FAIL_V_MSG(Vector<uint8_t>(), "Shader translation at stage " + String(shader_stage_names[stage]) + " failed.");
			}

			Vector<uint8_t> blob_copy;
			blob_copy.resize(dxil_blob.size);
			memcpy(blob_copy.ptrw(), dxil_blob.data, dxil_blob.size);
			blob_finish(&dxil_blob);
			dxil_blobs.insert(stage, blob_copy);
		}
	}

#if 0
	if (dxil_blobs.has(SHADER_STAGE_FRAGMENT)) {
		Ref<FileAccess> f = FileAccess::open("res://1.dxil", FileAccess::WRITE);
		f->store_buffer(dxil_blobs[SHADER_STAGE_FRAGMENT].ptr(), dxil_blobs[SHADER_STAGE_FRAGMENT].size());
	}
#endif

	// Patch with default values of specialization constants.
	if (specialization_constants.size()) {
		for (const RenderingDeviceD3D12ShaderBinarySpecializationConstant &sc : specialization_constants) {
			_shader_patch_dxil_specialization_constant((PipelineSpecializationConstantType)sc.type, &sc.int_value, sc.stages_bit_offsets, dxil_blobs, true);
		}
#if 0
		if (dxil_blobs.has(SHADER_STAGE_FRAGMENT)) {
			Ref<FileAccess> f = FileAccess::open("res://2.dxil", FileAccess::WRITE);
			f->store_buffer(dxil_blobs[SHADER_STAGE_FRAGMENT].ptr(), dxil_blobs[SHADER_STAGE_FRAGMENT].size());
		}
#endif
	}

	// Sign.
	for (KeyValue<ShaderStage, Vector<uint8_t>> &E : dxil_blobs) {
		ShaderStage stage = E.key;
		Vector<uint8_t> &dxil_blob = E.value;
		bool sign_ok = _shader_sign_dxil_bytecode(stage, dxil_blob);
		ERR_FAIL_COND_V(!sign_ok, Vector<uint8_t>());
	}

	// Build the root signature.
	ComPtr<ID3DBlob> root_sig_blob;
	{
		auto stages_to_d3d12_visibility = [](uint32_t p_stages_mask) -> D3D12_SHADER_VISIBILITY {
			switch (p_stages_mask) {
				case SHADER_STAGE_VERTEX_BIT: {
					return D3D12_SHADER_VISIBILITY_VERTEX;
				}
				case SHADER_STAGE_FRAGMENT_BIT: {
					return D3D12_SHADER_VISIBILITY_PIXEL;
				}
				default: {
					return D3D12_SHADER_VISIBILITY_ALL;
				}
			}
		};

		LocalVector<D3D12_ROOT_PARAMETER1> root_params;

		// Root (push) constants.
		if (binary_data.dxil_push_constant_stages) {
			CD3DX12_ROOT_PARAMETER1 push_constant;
			push_constant.InitAsConstants(
					binary_data.push_constant_size / sizeof(uint32_t),
					ROOT_CONSTANT_REGISTER,
					ROOT_CONSTANT_SPACE,
					stages_to_d3d12_visibility(binary_data.dxil_push_constant_stages));
			root_params.push_back(push_constant);
		}

		// NIR-DXIL runtime data.
		if (binary_data.nir_runtime_data_root_param_idx == 1) { // Set above to 1 when discovering runtime data is needed.
			DEV_ASSERT(!binary_data.is_compute); // Could be supported if needed, but it's pointless as of now.
			binary_data.nir_runtime_data_root_param_idx = root_params.size();
			CD3DX12_ROOT_PARAMETER1 nir_runtime_data;
			nir_runtime_data.InitAsConstants(
					sizeof(dxil_spirv_vertex_runtime_data) / sizeof(uint32_t),
					RUNTIME_DATA_REGISTER,
					RUNTIME_DATA_SPACE,
					D3D12_SHADER_VISIBILITY_VERTEX);
			root_params.push_back(nir_runtime_data);
		}

		// Descriptor tables (up to two per uniform set, for resources and/or samplers).

		// These have to stay around until serialization!
		struct TraceableDescriptorTable {
			uint32_t stages_mask = {};
			Vector<D3D12_DESCRIPTOR_RANGE1> ranges;
			Vector<RenderingDeviceD3D12ShaderBinaryDataBinding::RootSignatureLocation *> root_sig_locations;
		};
		Vector<TraceableDescriptorTable> resource_tables_maps;
		Vector<TraceableDescriptorTable> sampler_tables_maps;

		for (int set = 0; set < uniform_info.size(); set++) {
			bool first_resource_in_set = true;
			bool first_sampler_in_set = true;
			uniform_info.write[set].sort();
			for (int i = 0; i < uniform_info[set].size(); i++) {
				const RenderingDeviceD3D12ShaderBinaryDataBinding &binding = uniform_info[set][i];

				bool really_used = binding.dxil_stages != 0;
#ifdef DEV_ENABLED
				bool anybody_home = (ResourceClass)binding.res_class != RES_CLASS_INVALID || binding.has_sampler;
				DEV_ASSERT(anybody_home == really_used);
#endif
				if (!really_used) {
					continue; // Existed in SPIR-V; went away in DXIL.
				}

				auto insert_range = [](D3D12_DESCRIPTOR_RANGE_TYPE p_range_type,
											uint32_t p_num_descriptors,
											uint32_t p_dxil_register,
											uint32_t p_dxil_stages_mask,
											RenderingDeviceD3D12ShaderBinaryDataBinding::RootSignatureLocation(&p_root_sig_locations),
											Vector<TraceableDescriptorTable> &r_tables,
											bool &r_first_in_set) {
					if (r_first_in_set) {
						r_tables.resize(r_tables.size() + 1);
						r_first_in_set = false;
					}
					TraceableDescriptorTable &table = r_tables.write[r_tables.size() - 1];
					table.stages_mask |= p_dxil_stages_mask;

					CD3DX12_DESCRIPTOR_RANGE1 range;
					// Due to the aliasing hack for SRV-UAV of different families,
					// we can be causing an unintended change of data (sometimes the validation layers catch it).
					D3D12_DESCRIPTOR_RANGE_FLAGS flags = D3D12_DESCRIPTOR_RANGE_FLAG_NONE;
					if (p_range_type == D3D12_DESCRIPTOR_RANGE_TYPE_SRV || p_range_type == D3D12_DESCRIPTOR_RANGE_TYPE_UAV) {
						flags = D3D12_DESCRIPTOR_RANGE_FLAG_DATA_VOLATILE;
					} else if (p_range_type == D3D12_DESCRIPTOR_RANGE_TYPE_CBV) {
						flags = D3D12_DESCRIPTOR_RANGE_FLAG_DATA_STATIC_WHILE_SET_AT_EXECUTE;
					}
					range.Init(p_range_type, p_num_descriptors, p_dxil_register, 0, flags);

					table.ranges.push_back(range);
					table.root_sig_locations.push_back(&p_root_sig_locations);
				};

				uint32_t num_descriptors = 1;

				D3D12_DESCRIPTOR_RANGE_TYPE resource_range_type = {};
				switch ((ResourceClass)binding.res_class) {
					case RES_CLASS_INVALID: {
						num_descriptors = binding.length;
						DEV_ASSERT(binding.has_sampler);
					} break;
					case RES_CLASS_CBV: {
						resource_range_type = D3D12_DESCRIPTOR_RANGE_TYPE_CBV;
						DEV_ASSERT(!binding.has_sampler);
					} break;
					case RES_CLASS_SRV: {
						resource_range_type = D3D12_DESCRIPTOR_RANGE_TYPE_SRV;
						num_descriptors = MAX(1u, binding.length); // An unbound R/O buffer is reflected as zero-size.
					} break;
					case RES_CLASS_UAV: {
						resource_range_type = D3D12_DESCRIPTOR_RANGE_TYPE_UAV;
						num_descriptors = MAX(1u, binding.length); // An unbound R/W buffer is reflected as zero-size.
						DEV_ASSERT(!binding.has_sampler);
					} break;
				}

				uint32_t dxil_register = set * GODOT_NIR_DESCRIPTOR_SET_MULTIPLIER + binding.binding * GODOT_NIR_BINDING_MULTIPLIER;

				if (binding.res_class != RES_CLASS_INVALID) {
					insert_range(
							resource_range_type,
							num_descriptors,
							dxil_register,
							uniform_info[set][i].dxil_stages,
							uniform_info.write[set].write[i].root_sig_locations[RS_LOC_TYPE_RESOURCE],
							resource_tables_maps,
							first_resource_in_set);
				}
				if (binding.has_sampler) {
					insert_range(
							D3D12_DESCRIPTOR_RANGE_TYPE_SAMPLER,
							num_descriptors,
							dxil_register,
							uniform_info[set][i].dxil_stages,
							uniform_info.write[set].write[i].root_sig_locations[RS_LOC_TYPE_SAMPLER],
							sampler_tables_maps,
							first_sampler_in_set);
				}
			}
		}

		auto make_descriptor_tables = [&root_params, &stages_to_d3d12_visibility](const Vector<TraceableDescriptorTable> &p_tables) {
			for (const TraceableDescriptorTable &table : p_tables) {
				D3D12_SHADER_VISIBILITY visibility = stages_to_d3d12_visibility(table.stages_mask);
				DEV_ASSERT(table.ranges.size() == table.root_sig_locations.size());
				for (int i = 0; i < table.ranges.size(); i++) {
					// By now we know very well which root signature location corresponds to the pointed uniform.
					table.root_sig_locations[i]->root_param_idx = root_params.size();
					table.root_sig_locations[i]->range_idx = i;
				}

				CD3DX12_ROOT_PARAMETER1 root_table;
				root_table.InitAsDescriptorTable(table.ranges.size(), table.ranges.ptr(), visibility);
				root_params.push_back(root_table);
			}
		};

		make_descriptor_tables(resource_tables_maps);
		make_descriptor_tables(sampler_tables_maps);

		CD3DX12_VERSIONED_ROOT_SIGNATURE_DESC root_sig_desc = {};
		D3D12_ROOT_SIGNATURE_FLAGS root_sig_flags =
				D3D12_ROOT_SIGNATURE_FLAG_DENY_HULL_SHADER_ROOT_ACCESS |
				D3D12_ROOT_SIGNATURE_FLAG_DENY_DOMAIN_SHADER_ROOT_ACCESS |
				D3D12_ROOT_SIGNATURE_FLAG_DENY_GEOMETRY_SHADER_ROOT_ACCESS |
				D3D12_ROOT_SIGNATURE_FLAG_DENY_AMPLIFICATION_SHADER_ROOT_ACCESS |
				D3D12_ROOT_SIGNATURE_FLAG_DENY_MESH_SHADER_ROOT_ACCESS;
		if (!stages_processed.has_flag(SHADER_STAGE_VERTEX_BIT)) {
			root_sig_flags |= D3D12_ROOT_SIGNATURE_FLAG_DENY_VERTEX_SHADER_ROOT_ACCESS;
		}
		if (!stages_processed.has_flag(SHADER_STAGE_FRAGMENT_BIT)) {
			root_sig_flags |= D3D12_ROOT_SIGNATURE_FLAG_DENY_PIXEL_SHADER_ROOT_ACCESS;
		}
		if (binary_data.vertex_input_mask) {
			root_sig_flags |= D3D12_ROOT_SIGNATURE_FLAG_ALLOW_INPUT_ASSEMBLER_INPUT_LAYOUT;
		}
		root_sig_desc.Init_1_1(root_params.size(), root_params.ptr(), 0, nullptr, root_sig_flags);

		ComPtr<ID3DBlob> error_blob;
		HRESULT res = D3DX12SerializeVersionedRootSignature(&root_sig_desc, D3D_ROOT_SIGNATURE_VERSION_1_1, root_sig_blob.GetAddressOf(), error_blob.GetAddressOf());
		ERR_FAIL_COND_V_MSG(res, Vector<uint8_t>(),
				"Serialization of root signature failed with error " + vformat("0x%08ux", res) + " and the following message:\n" + String((char *)error_blob->GetBufferPointer(), error_blob->GetBufferSize()));

		binary_data.root_signature_crc = crc32(0, nullptr, 0);
		binary_data.root_signature_crc = crc32(binary_data.root_signature_crc, (const Bytef *)root_sig_blob->GetBufferPointer(), root_sig_blob->GetBufferSize());
	}

	Vector<Vector<uint8_t>> compressed_stages;
	Vector<uint32_t> zstd_size;

	uint32_t stages_binary_size = 0;

	for (int i = 0; i < p_spirv.size(); i++) {
		Vector<uint8_t> zstd;
		Vector<uint8_t> &dxil_blob = dxil_blobs[p_spirv[i].shader_stage];
		zstd.resize(Compression::get_max_compressed_buffer_size(dxil_blob.size(), Compression::MODE_ZSTD));
		int dst_size = Compression::compress(zstd.ptrw(), dxil_blob.ptr(), dxil_blob.size(), Compression::MODE_ZSTD);

		zstd_size.push_back(dst_size);
		zstd.resize(dst_size);
		compressed_stages.push_back(zstd);

		uint32_t s = compressed_stages[i].size();
		if (s % 4 != 0) {
			s += 4 - (s % 4);
		}
		stages_binary_size += s;
	}

	CharString shader_name_utf = p_shader_name.utf8();

	binary_data.shader_name_len = shader_name_utf.length();

	uint32_t total_size = sizeof(uint32_t) * 3; // Header + version + main datasize;.
	total_size += sizeof(RenderingDeviceD3D12ShaderBinaryData);

	total_size += binary_data.shader_name_len;
	if ((binary_data.shader_name_len % 4) != 0) { // Alignment rules are really strange.
		total_size += 4 - (binary_data.shader_name_len % 4);
	}

	for (int i = 0; i < uniform_info.size(); i++) {
		total_size += sizeof(uint32_t);
		total_size += uniform_info[i].size() * sizeof(RenderingDeviceD3D12ShaderBinaryDataBinding);
	}

	total_size += sizeof(RenderingDeviceD3D12ShaderBinarySpecializationConstant) * specialization_constants.size();

	total_size += compressed_stages.size() * sizeof(uint32_t) * 3; // Sizes.
	total_size += stages_binary_size;

	binary_data.root_signature_len = root_sig_blob->GetBufferSize();
	total_size += binary_data.root_signature_len;

	Vector<uint8_t> ret;
	ret.resize(total_size);
	{
		uint32_t offset = 0;
		uint8_t *binptr = ret.ptrw();
		binptr[0] = 'G';
		binptr[1] = 'S';
		binptr[2] = 'B';
		binptr[3] = 'D'; // Godot shader binary data.
		offset += 4;
		encode_uint32(SHADER_BINARY_VERSION, binptr + offset);
		offset += sizeof(uint32_t);
		encode_uint32(sizeof(RenderingDeviceD3D12ShaderBinaryData), binptr + offset);
		offset += sizeof(uint32_t);
		memcpy(binptr + offset, &binary_data, sizeof(RenderingDeviceD3D12ShaderBinaryData));
		offset += sizeof(RenderingDeviceD3D12ShaderBinaryData);
		memcpy(binptr + offset, shader_name_utf.ptr(), binary_data.shader_name_len);
		offset += binary_data.shader_name_len;

		if ((binary_data.shader_name_len % 4) != 0) { // Alignment rules are really strange.
			offset += 4 - (binary_data.shader_name_len % 4);
		}

		for (int i = 0; i < uniform_info.size(); i++) {
			int count = uniform_info[i].size();
			encode_uint32(count, binptr + offset);
			offset += sizeof(uint32_t);
			if (count > 0) {
				memcpy(binptr + offset, uniform_info[i].ptr(), sizeof(RenderingDeviceD3D12ShaderBinaryDataBinding) * count);
				offset += sizeof(RenderingDeviceD3D12ShaderBinaryDataBinding) * count;
			}
		}

		if (specialization_constants.size()) {
			memcpy(binptr + offset, specialization_constants.ptr(), sizeof(RenderingDeviceD3D12ShaderBinarySpecializationConstant) * specialization_constants.size());
			offset += sizeof(RenderingDeviceD3D12ShaderBinarySpecializationConstant) * specialization_constants.size();
		}

		for (int i = 0; i < compressed_stages.size(); i++) {
			encode_uint32(p_spirv[i].shader_stage, binptr + offset);
			offset += sizeof(uint32_t);
			encode_uint32(dxil_blobs[p_spirv[i].shader_stage].size(), binptr + offset);
			offset += sizeof(uint32_t);
			encode_uint32(zstd_size[i], binptr + offset);
			offset += sizeof(uint32_t);
			memcpy(binptr + offset, compressed_stages[i].ptr(), compressed_stages[i].size());

			uint32_t s = compressed_stages[i].size();

			if (s % 4 != 0) {
				s += 4 - (s % 4);
			}

			offset += s;
		}

		memcpy(binptr + offset, root_sig_blob->GetBufferPointer(), root_sig_blob->GetBufferSize());
		offset += root_sig_blob->GetBufferSize();

		ERR_FAIL_COND_V(offset != (uint32_t)ret.size(), Vector<uint8_t>());
	}

	return ret;
}

}
